const fetch = require('node-fetch');
const parser = require('fast-xml-parser');
const https = require('https');

const agent = new https.Agent({
  rejectUnauthorized: false,
});

const fetch_sitemap = (url, timeout = 60000) =>
  fetch(url, { timeout, agent })
    .then(res => res.text())
    .then(xml => {
      const { sitemapindex, urlset } = parser.parse(xml);

      // sitemap contains URLs directly, return them
      if (urlset)
        // Sitemap contains URLs directly, return them
        return urlset.url.loc
          ? urlset.url.loc // Only single URL in sitemap
          : urlset.url.map(link => link.loc); // Multiple URLs. in sitemap

      // Sitemap contains URLs to other sitemap(s), download them resursively
      if (sitemapindex) {
        // Contains only a single sitemap
        if (sitemapindex.sitemap.loc)
          return Promise.all([
            fetch_sitemap(sitemapindex.sitemap.loc),
          ]);

        // Recursively fetch all sitemaps inside current sitemap and fetch links
        // Using Promise.all() for running in parallel
        return Promise.all(
          sitemapindex.sitemap.map(sitemap =>
            fetch_sitemap(sitemap.loc),
          ),
        );
      }

      // Something else, return empty array
      return [];
    })
    .catch(e => console.log(e));

const get_sitemap_links = async (url, timeout) => {
  try {
    // Fetch sitemap recursively
    let links = await fetch_sitemap(url, timeout);

    // Flattern array
    links = links.flat(Infinity);

    // Get only unique links
    links = [...new Set(links)];
    return links;
  } catch (e) {
    throw new Error('Unable to fetch sitemap.', e);
  }
};

module.exports = get_sitemap_links;
